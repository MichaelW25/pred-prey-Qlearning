{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcc3fab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d43e116",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTIONS = {'U': (-1, 0), 'D': (1, 0), 'L': (0, -1), 'R': (0, 1)}\n",
    "class Planet(object):\n",
    "    def __init__(self):\n",
    "        # start with defining your planet\n",
    "        self.planet = np.zeros((6, 6))\n",
    "        self.planet[2, 1] = 2\n",
    "        self.planet[3, 4] = 1\n",
    "        self.planet[4, 2] = 1\n",
    "        self.planet[0, 2] = 1\n",
    "        self.planet[2, 0] = 1\n",
    "        self.robot_position = (1, 2) # current robot position\n",
    "        self.steps = 0 # contains num steps robot took\n",
    "        self.allowed_states = None # for now, this is none\n",
    "        self.construct_allowed_states() \n",
    "    def is_allowed_move(self, state, action):\n",
    "        y, x = state\n",
    "        y += ACTIONS[action][0]\n",
    "        x += ACTIONS[action][1]\n",
    "        # moving off the board\n",
    "        if y < 0 or x < 0 or y > 5 or x > 5:\n",
    "             return False\n",
    "        # moving into start position or empty space\n",
    "        if self.planet[y, x] == 0 or self.planet[y, x] == 2:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    def construct_allowed_states(self):\n",
    "        allowed_states = {}\n",
    "        for y, row in enumerate(self.planet):\n",
    "            for x, col in enumerate(row):\n",
    "                # iterate through all valid spaces\n",
    "                if self.planet[(y,x)] != 1:\n",
    "                    allowed_states[(y,x)] = []\n",
    "                    for action in ACTIONS:\n",
    "                        if self.is_allowed_move((y, x), action):\n",
    "                            allowed_states[(y,x)].append(action)\n",
    "        self.allowed_states = allowed_states\n",
    "    def update_planet(self, action):\n",
    "        y, x = self.robot_position\n",
    "        self.planet[y, x] = 0 # set the current position to empty\n",
    "        y += ACTIONS[action][0]\n",
    "        x += ACTIONS[action][1]\n",
    "        self.robot_position = (y, x)\n",
    "        self.planet[y, x] = 2\n",
    "        self.steps += 1\n",
    "    def is_game_over(self):\n",
    "        if self.robot_position == (5, 5):\n",
    "            return True\n",
    "        return False\n",
    "    def give_reward(self, state_history):\n",
    "        if self.robot_position == (5, 5):\n",
    "            return 0\n",
    "        else:\n",
    "            return -1\n",
    "    def get_state_and_reward(self, state_history):\n",
    "        return self.robot_position, self.give_reward(state_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2249e401",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTIONS = {'U': (-1, 0), 'D': (1, 0), 'L': (0, -1), 'R': (0, 1)}\n",
    "class Agent(object):\n",
    "    def __init__(self, states, alpha=0.15, random_factor=0.2):\n",
    "        self.state_history = [((0, 0), 0)] # state, reward\n",
    "        self.alpha = alpha\n",
    "        self.random_factor = random_factor\n",
    "        \n",
    "        # start the rewards table\n",
    "        self.G = {}\n",
    "        self.init_reward(states)\n",
    "    def init_reward(self, states):\n",
    "        for i, row in enumerate(states):\n",
    "            for j, col in enumerate(row):\n",
    "                self.G[(j,i)] = np.random.uniform(high=1.0, low=0.1)\n",
    "    def update_state_history(self, state, reward):\n",
    "        self.state_history.append((state, reward))\n",
    "    def learn(self):\n",
    "        target = 0 # we know the \"ideal\" reward\n",
    "        a = self.alpha\n",
    "        for state, reward in reversed(self.state_history):\n",
    "            self.G[state] = (1-a) * self.G[state] + a * target #self.G[state]+ a * (target - self.G[state])\n",
    "        self.state_history = [] # reset the state_history\n",
    "        self.random_factor -= 10e-5 # decrease random_factor\n",
    "    def choose_action(self, state, allowed_moves):\n",
    "        next_move = None\n",
    "        n = np.random.random()\n",
    "        if n < self.random_factor:\n",
    "            next_move = np.random.choice(allowed_moves)\n",
    "        else:\n",
    "            maxG = -10e15 # some really small random number\n",
    "            for action in allowed_moves:\n",
    "                new_state = tuple([sum(x) for x in zip(state, ACTIONS[action])])\n",
    "                if self.G[new_state] >= maxG:\n",
    "                    next_move = action\n",
    "                    maxG = self.G[new_state]\n",
    "        return next_move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b5a4f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    planet = Planet()\n",
    "    robot = Agent(planet.planet, alpha=0.001, random_factor=0.25)\n",
    "    moveHistory = []\n",
    "\n",
    "    for i in range(15000):\n",
    "        if i % 1000 == 0:            \n",
    "            print(i)\n",
    "            \n",
    "        while not planet.is_game_over():\n",
    "            sHistory = robot.state_history\n",
    "            state, _ = planet.get_state_and_reward(sHistory) # get the current state\n",
    "            action = robot.choose_action(state, planet.allowed_states[state]) # choose an action (explore or exploit)\n",
    "            planet.update_planet(action) # update the planet according to the action\n",
    "            state, reward = planet.get_state_and_reward(sHistory) # get the new state and reward\n",
    "            robot.update_state_history(state, reward) # update the robot memory with state and reward\n",
    "            if planet.steps > 1000:\n",
    "                # end the robot if it takes too long to find the goal\n",
    "                planet.robot_position = (5, 5)\n",
    "\n",
    "        robot.learn() # robot should learn after every episode\n",
    "        if planet.steps < 1000:\n",
    "            moveHistory.append(planet.steps) # get a history of number of steps taken to plot later\n",
    "        planet = Planet() # reinitialize the planet\n",
    "        \n",
    "plt.figure(figsize=(18, 10))\n",
    "plt.semilogy(moveHistory, \"b\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846182aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "testHistory = []\n",
    "for i in range(2000):\n",
    "        if i % 1000 == 0:            \n",
    "            print(i)\n",
    "            \n",
    "        planet = Planet()\n",
    "        while not planet.is_game_over():\n",
    "            sHistory = robot.state_history\n",
    "            state, _ = planet.get_state_and_reward(sHistory) # get the current state\n",
    "            action = robot.choose_action(state, planet.allowed_states[state]) # choose an action (explore or exploit)\n",
    "            planet.update_planet(action) # update the planet according to the action\n",
    "            state, reward = planet.get_state_and_reward(sHistory) # get the new state and reward\n",
    "            robot.update_state_history(state, reward) # update the robot memory with state and reward\n",
    "            if planet.steps > 1000:\n",
    "                # end the robot if it takes too long to find the goal\n",
    "                planet.robot_position = (5, 5)\n",
    "            #print(planet.planet)\n",
    "        testHistory.append(planet.steps)\n",
    "plt.semilogy(testHistory, \"b--\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
